= InstructLab


image::instructlab-banner.png[width=640]

InstructLab is a model-agnostic open-source AI project that facilitates contributions to Large Language Models (LLMs).

---

=== Overview
InstructLab is an open source project for enhancing large language models (LLMs) used in generative artificial intelligence (gen AI) applications. Created by IBM and Red Hat, the InstructLab community project provides a cost-effective solution for improving the alignment of LLMs and opens the doors for those with minimal machine learning experience to contribute.

AI practitioners often need to adapt a pretrained LLM to suit a particular business purpose. InstructLab can enhance an LLM using far less human-generated information and far fewer computing resources than are typically used to retrain a model. 


=== How does InstructLab work?

The LAB method consists of 3 components:

 . *Taxonomy-driven data curation.* Taxonomy is a set of diverse training data curated by humans as examples of new knowledge and skills for the model.
 . *Large-scale synthetic data generation.* The model is then used to generate new examples based on the seed training data. Recognizing that synthetic data can vary in quality, the LAB method adds an automated step to refine the example answers, making sure they’re grounded and safe.
 . *Iterative, large-scale alignment tuning.* Finally, the model is retrained based on the set of synthetic data. The LAB method includes two tuning phases: knowledge tuning, followed by skill tuning.



=== Alignment tuning
After pretraining, LLMs undergo alignment tuning to make the model’s answers as accurate and useful as possible. The first step in alignment tuning is typically instruction tuning, in which a model is trained directly on specific tasks of interest. Next is preference tuning, which can include *reinforcement learning from human feedback* (RLHF). In this step, humans test the model and rate its output, noting if the model’s answers are preferred or unpreferred. An RLHF process may include multiple rounds of feedback and refinement to optimize a model.

Researchers have found that the amount of feedback at this alignment tuning stage can be much smaller than the initial set of training data―tens of thousands of human annotations, compared to the trillions of tokens of data required for pretraining―and still unlock latent capabilities of the model.

=== InstructLab
The LAB method emerged from the idea that it should be possible to realize the benefits of model alignment from an even smaller set of human-generated data. An AI model can use a handful of human examples to generate a large amount of synthetic data―then refine that list for quality―and use that high-quality synthetic data set for further tuning and training. In contrast to instruction tuning, which typically need thousands of examples of human feedback, LAB can make a model significantly better using relatively few examples provided by humans.

---

How is InstructLab different from retrieval-augmented generation (RAG)?
The short answer is InstructLab and retrieval-augmented generation (RAG) solve different problems.

RAG is a cost-efficient method for supplementing an LLM with domain-specific knowledge that wasn’t part of its pretraining. RAG makes it possible for a chatbot to accurately answer questions related to a specific field or business without retraining the model. Knowledge documents are stored in a vector database, then retrieved in chunks and sent to the model as part of user queries. This is helpful for anyone who wants to add proprietary data to an LLM without giving up control of their information, or who needs an LLM to access timely information. 

This is in contrast to the InstructLab method, which sources end-user contributions to support regular builds of an enhanced version of an LLM. InstructLab helps add knowledge and unlock new skills of an LLM.

It’s possible to "supercharge" a RAG process by using the RAG technique on an InstructLab-tuned model.

=== Why InstructLab


The project enables community contributors to add additional "skills" or "knowledge" to a particular model.

InstructLab's model-agnostic technology gives model upstreams with sufficient infrastructure resources, the ability to create regular builds of their open-source licensed models not by rebuilding and retraining the entire model but by composing new skills into it.

View the original article https://www.redhat.com/en/topics/ai/what-is-instructlab[What is instructlab at Redhat.com]

Take a look at "lab-enhanced" models on the https://huggingface.co/instructlab[InstructLab Hugging Face page].

---

// ===  Optional Lab: https://github.com/RedHatQuickCourses/instructlab-insurance-lab/tree/main

=== InstructLab Unleashed --*COMING SOON*


InstructLab Unleashed: Training the Merlinite Model to Answer Questions for Parasol Insurance!
This training lab focuses on equipping the Merlinite AI model with the capability to handle and respond to queries related to Parasol Insurance using InstructLab.

You will learn how to train the model using specific datasets and techniques to ensure it can accurately and efficiently provide answers to common insurance-related questions.

By the end of the training, you will have a comprehensive understanding of the processes involved in fine-tuning AI models for specialized applications within the insurance industry.


