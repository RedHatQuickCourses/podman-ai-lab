= Recipe Catalog

Podman AI Lab ships with a *_Recipes Catalog_* that helps you navigate a number of core AI use cases and problem domains such as ChatBots, Code Generators and Text Summarizers. Each recipe comes with detailed explanations and sample applications with open source code that can be run with various large language models (LLMs). Experimenting with multiple models allows finding the optimal one for our use case.

=== GizmoGobble team's use of Recipe Catalog

The main goal of GizmoGenie application is to provide a ChatBot style interaction for web customers. Now that GG's Development team has evaluated a few AI models using the playground and model services. It is time to test their selections in a simulated ChatBot application that mirrors the web interface solution.

In the natural language section of the AI Lab Recipe Catalog, there is a recipe for a Chat application that provides features similar to the planned containerized version of the  GizmoGenie Chat interface.

The best part about the Chat Application recipe is the provided links to a source github repository that contains the application code. This repo contains a recipe for building and running the containerized AI Model along with a second container that runs the front end application.  Both of these are built using Red Hat's Universal bases image, which is free to use for customers, and provide a re-usable stable container platform. 

These containerized AI recipes can be used to help developers quickly prototype new AI and LLM based applications locally, without the need for relying on any other externally hosted services. Since they are already containerized, it also helps developers move quickly from prototype to production.


image::start-ai-app.gif[width=640]

== Available categories of AI solutions

*natural language processing*

 * *Chatbots* that simulate human conversation, using AI to comprehend user inquiries and offer suitable responses. These capabilities are often used to augment applications that provide self-service customer support or virtual personal assistance.
 * *Text summarizers*, which provide versatile capabilities across many applications and industries, where they can deliver effective and efficient information management. Using this recipe, developers can build applications to assist with things like content creation and curation, research, news aggregation, social media monitoring, and language learning.
 * *Code generators*, which empower developers to concentrate on higher-level design and problem-solving by automating repetitive tasks like project setup and API integration, or to produce code templates.
 * - *coming soon* - *RAG (Retrieval Augmented Generation)*, is the process of optimizing the output of a large language model, so it references an authoritative knowledge base outside of its training data sources before generating a response.
 
*computer-vision* 

 * *Object detection* helps identify and locate objects within digital images or video frames. It is a fundamental component in various applications, including autonomous vehicles, retail inventory management, precision agriculture, and sports broadcasting.
 
*audio* 

 * *Audio-to-text* transcription involves the process of automatically transcribing spoken language into written text, facilitating documentation, accessibility, and analysis of audio content.

*multimodel* 

 * *Image understanding* upload an image file from your host machine and the app will provide a natural language description of the image.


== LAB: ChatBot Application Deployment

Located in the AI Apps section of the AI Lab is the Recipe Catalog, along with the Running menu option. 

When opened the recipe catalog displays the sample applications sorted by category. 

Let's begin with the ChatBot Application in the natural language section

 .  Select the ChatBot application, which will open a new dashboard with two options, the Summary & Models tabs.

 .. The Summary tab displays details about the application.   
 .. The Models tab allows the user to select a compatible model for the application to use.  
 
 . Depending on the available resources in your Podman container (machine) running in Podman desktop, you may receive a notification about increasing available resources to improve performance. 

 .. If you did receive this message, close out of the previous resources and restart your Podman container

 .. Or increase the resources available in your Podman container for a pleasant lab experience. 

 . On the right side of the window is the *AI App Details* section with a button to start the AI App.

 .. In the Model Section, there is a drop down to allow the user to select an alternative Model

 .. The model section option simples open the models tab described above.

 .. Also shown is the repository location for the AI lab recipes where the original application files are located

 . Click the Start AI App to launch the application. 

 ..  if the model selected has not been downloaded, it will be downloaded first.

 .. If you use a model other than the default, you may need to use the Running menu dashboard to view and launch the application once it's started.  Otherwise you will see all the details of the model starting process in the  AI App Details. 


If you use the default AI Model, then you will get a checklist of the progress during the application deployment.

Additionally, from the AI App Details sub-menu, there will also be options to open the application in a web browser, restart the application, and delete the application. 

The application can now be launched in a web browser to interact with the model via the ChaBot client.

This seems exactly like the playground, however the difference is how the application and model are served to work together.   

Another difference in this user experience is there are no tuning parameter options or system prompt provided to the user, as those will be set in the background by the developer and stay consistent across users.

=== Podman Desktop 

We can use the containers menu of Podman desktop to view the running container that make up this application.

 * There is a container for the streamlit chat application

 * There is a container for the llama.cpp server hosting the AI Model

 * There is a container for ???

In Pod section of Podman Desktop, the Pod that contains the three container is displayed

 .  view the kubernetes deployment

 . view the log files

 . view the summary of containers running in the pod


=== Additional applications

Each of the additional Recipe's available will launch a service to allow the user to develop experience with a specific business case for AI Model development. 

There is a video walkthrough of each of the additional Recipe's in action.

In between each, delete the previous recipe, restart the Podman container to experience the best Podman AI lab performance.




== Recipes catalog overview

One of the most important features of the Podman AI Lab extension is the curated catalog of open source recipes that enable you to navigate common AI use cases and solutions. 

To begin, click the top left option the Recipes Catalog menu option. 

This catalog is organized by categories of example use cases that can inspire you on how to infuse your app with AI, with pre-selected models (and the ability to swap), example code, and easy access to your IDE. The catalog of recipes is provided to provide the best practices and inspire you with use cases you can eventually benefit from in your applications. 

Once you've selected a recipe from the Recipes Catalog, you'll be able to see a summary of what the recipe does and how it works. This will give you a better understanding of the recipe's capabilities and help you decide if it's right for your application. You'll also find handy links to the application source code and the recommended model, as well as the ability to select other compatible models (curated from Hugging Face's open source community). 

When you're ready to see the application live and running, you can start it by clicking the Start AI App button on the upper right-hand side. As the application starts, you'll be able to see the model it uses and where the source code of the application is located. In the background, Podman is running an inference server for the downloaded model within a container using the freely redistributable Red Hat Enterprise Linux Universal Base Image.

During the startup process, you'll be shown a few steps that will be completed before the application is ready to use. These steps might include downloading the model, building the container images with the model and the application, etc.

Once the application has started, you can open it from the UI and use it from your web browser. In the chatbot example, we're able to interact with the front end application, which is inferencing the model server, the selected Mistral-7B model. Itâ€™s this easy to set up a model server and start integrating generative AI in your applications.

As you work in other areas of Podman Desktop for your container workflow, you'll always be able to see your running AI apps (i.e., the recipes you started) in the dedicated Running section for Podman AI Lab.




